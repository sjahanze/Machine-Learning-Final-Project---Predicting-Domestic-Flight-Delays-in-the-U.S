# -*- coding: utf-8 -*-
"""Predicting Domestic Flight Delays in the U.S

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p3XyvHvLpove5Z-igsp14Yv3Kcb8V5rt
"""

import pandas as pd
import pandas as pd
import numpy as np
from plotnine import *
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn import preprocessing
from sklearn.ensemble import BaggingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_score
from sklearn.inspection import partial_dependence
import matplotlib.pyplot as plt
import dtreeviz
from plotnine import ggplot, aes, geom_line, geom_point, labs, theme_minimal, theme, element_blank, geom_col, coord_flip, scale_y_continuous, facet_wrap
import xgboost as xgb
from tqdm.notebook import tqdm
from sklearn.metrics import roc_curve, roc_auc_score
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn import preprocessing
from sklearn.ensemble import BaggingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_score
from sklearn.inspection import partial_dependence
import matplotlib.pyplot as plt
import dtreeviz
from plotnine import ggplot, aes, geom_line, geom_point, labs, theme_minimal, theme, element_blank, geom_col, coord_flip, scale_y_continuous, facet_wrap
import xgboost as xgb
import shap

!pip install dtreeviz

pip install "xgboost==3.0.3" "shap==0.49.1"

data = pd.read_csv("/content/flights_sample_3m.csv")
data
sample = data.iloc[:150000]

sample.describe(include= 'all')

g1 = (ggplot(sample, aes(x = "DEP_DELAY", fill = ('factor(ARR_DELAY > 15)')))
      + geom_density(alpha = 0.5)
      + labs( x= 'Departure Delay',
             title='Departure Delay - Arrival Delay'))
g1

g2 = (ggplot(sample, aes(x = 'DISTANCE', fill = ('factor(ARR_DELAY > 15)')))
      + geom_density(alpha = 0.5)
      + labs( x= 'Distance',
             title='Distance- Arrival Delay')
      )
g2

g3 = (ggplot(sample, aes(x = 'AIR_TIME', fill = ('factor(ARR_DELAY > 15)')))
      + geom_density(alpha = 0.5)
      + labs( x= 'Air Time',
             title= 'Air Time - Arrival Delay'))
g3

# Group by airline and calculate mean delay rate
delay_by_airline = sample.groupby('AIRLINE_CODE')['ARR_DELAY'].mean().sort_values(ascending=False)

# Plot
plt.figure(figsize=(12, 6))
sns.barplot(x=delay_by_airline.index, y=delay_by_airline.values, palette='viridis')
plt.title("Proportion of Delayed Flights by Airline")
plt.xlabel("Airline Code")
plt.ylabel("Fraction of Flights Delayed (>15 mins)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#Cleaning the data by removing cancelled and diverted flights
df = sample[(sample['CANCELLED'] == 0) & (sample['DIVERTED'] == 0)].copy()

# Create binary classification target: 1 if delayed over 15 mins, else 0
df['DELAYED'] = (df['ARR_DELAY'].astype(float) > 15).astype(int)

# Quick check of class distribution
print(df['DELAYED'].value_counts())
df[['ARR_DELAY', 'DELAYED']].head()

delay_cols = [
    'DELAY_DUE_CARRIER',
    'DELAY_DUE_WEATHER',
    'DELAY_DUE_NAS',
    'DELAY_DUE_SECURITY',
    'DELAY_DUE_LATE_AIRCRAFT'
]

df[delay_cols] = df[delay_cols].fillna(0)

# Confirm no more NaNs in those columns
print(df[delay_cols].isna().sum())
df[delay_cols].describe()

# Ensure FL_DATE is datetime
df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])

# 1. Extract hour from scheduled departure time (CRS_DEP_TIME is in HHMM format)
df['DEP_HOUR'] = pd.to_datetime(df['CRS_DEP_TIME'].astype(str).str.zfill(4), format='%H%M', errors='coerce').dt.hour

# 2. Cyclical encoding
df['DEP_HOUR_SIN'] = np.sin(2 * np.pi * df['DEP_HOUR'] / 24)
df['DEP_HOUR_COS'] = np.cos(2 * np.pi * df['DEP_HOUR'] / 24)

# 3. Day of week (0 = Monday), and Month
df['DAY_OF_WEEK'] = df['FL_DATE'].dt.dayofweek
df['MONTH'] = df['FL_DATE'].dt.month

# Preview to confirm
df[['CRS_DEP_TIME', 'DEP_HOUR', 'DEP_HOUR_SIN', 'DEP_HOUR_COS', 'DAY_OF_WEEK', 'MONTH']].head()

# Plotting hour encoding on a unit circle to check if cylical encoding is correct
plt.figure(figsize=(6, 6))
plt.scatter(df['DEP_HOUR_COS'], df['DEP_HOUR_SIN'], alpha=0.5)
plt.title("Cyclical Encoding of Scheduled Departure Hour")
plt.xlabel("Cosine")
plt.ylabel("Sine")
plt.axis("equal")
plt.grid(True)
plt.show()

# 1. One-hot encode airline
df = pd.get_dummies(df, columns=['AIRLINE_CODE'], prefix='AIRLINE', drop_first=True)

# 2. Drop non-useful columns
drop_cols = [
    'AIRLINE', 'AIRLINE_DOT', 'FL_NUMBER', 'ORIGIN_CITY', 'DEST_CITY',
    'WHEELS_OFF', 'WHEELS_ON', 'ARR_TIME', 'DEP_TIME',
    'FL_DATE', 'CANCELLATION_CODE'
]
df.drop(columns=drop_cols, inplace=True, errors='ignore')

# Preview remaining columns
print(df.columns.tolist())

# 1. Define route column
df['ROUTE'] = df['ORIGIN'] + '-' + df['DEST']

# 2. Keep only frequent routes (e.g., at least 30 flights)
route_counts = df['ROUTE'].value_counts()
valid_routes = route_counts[route_counts >= 30].index
df = df[df['ROUTE'].isin(valid_routes)].copy()

# 3. Drop ROUTE, ORIGIN, DEST if not needed
df.drop(columns=['ROUTE', 'ORIGIN', 'DEST'], inplace=True)

# Check remaining data shape
print("Filtered dataset shape:", df.shape)

df.to_csv("sample_flights_data.csv", index=False)

sns.countplot(x='DELAYED', data=df)
plt.title("Distribution of Delayed vs. On-Time Flights")
plt.xlabel("Delayed (>15 min)")
plt.ylabel("Count")
plt.show()

airline_cols = [col for col in df.columns if col.startswith('AIRLINE_')]
df['AIRLINE'] = df[airline_cols].idxmax(axis=1).str.replace('AIRLINE_', '')

airline_delays = df.groupby('AIRLINE')['DELAYED'].mean().sort_values(ascending=False)

sns.barplot(x=airline_delays.index, y=airline_delays.values)
plt.title("Proportion of Delays by Airline")
plt.ylabel("Delay Rate")
plt.xticks(rotation=45)
plt.show()

hourly_delay = df.groupby('DEP_HOUR')['DELAYED'].mean()

sns.lineplot(x=hourly_delay.index, y=hourly_delay.values)
plt.title("Delay Rate by Hour of Scheduled Departure")
plt.xlabel("Hour of Day")
plt.ylabel("Delay Rate")
plt.grid(True)
plt.show()

sns.kdeplot(data=df, x='DEP_DELAY', hue='DELAYED', common_norm=False)
plt.title("Departure Delay Distribution by Arrival Delay Outcome")
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', center=0, annot=False)
plt.title("Correlation Matrix")
plt.show()

"""**BAGGING MODEL**"""

df.head()

# Define target
y = df['DELAYED']

# Drop columns not usable for modeling (you can add/remove as needed)
drop_cols = ['DELAYED', 'ARR_DELAY', 'DEP_DELAY', 'CRS_DEP_TIME', 'CRS_ARR_TIME',
             'DOT_CODE', 'CANCELLED', 'DIVERTED']

# Features to use (excluding known label leakage and irrelevant fields)
X = df.drop(columns=drop_cols + delay_cols)

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Encode labels for visualziation
le = preprocessing.LabelEncoder()
y_train_enc = le.fit_transform(y_train)

base_tree = DecisionTreeClassifier(random_state=123)
bag_model = BaggingClassifier(
    estimator=base_tree,
    n_estimators=100,        # number of trees
    max_samples=1.0,         # bootstrap sample size (fraction of training set)
    max_features=1.0,        # use all features per base estimator
    bootstrap=True,          # sample rows with replacement
    bootstrap_features=False,# do not bootstrap features
    oob_score=True,          # get OOB estimate
    n_jobs=-1,               # use all cores
    random_state=123
)

bag_model.fit(X_train, y_train_enc)

print(f"OOB Accuracy (Bagging): {bag_model.oob_score_:.4f}") # Check OOB Accuracy

y_pred_enc = bag_model.predict(X_test)
y_pred     = le.inverse_transform(y_pred_enc)

acc = accuracy_score(y_test, y_pred)
print(f"Bagging (Decision Trees) Accuracy on Test Set: {acc:.4f}")

labels_in_order = list(le.classes_)  # ensure consistent label order
cm = confusion_matrix(y_test, y_pred, labels=labels_in_order) # Create confusion matrix

# Generate confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_in_order)
disp.plot(cmap="Blues") # Set colors
plt.title("Confusion Matrix — Bagging") # Set title
plt.show() # Display plot

"""**XG BOOST**"""

y_test_enc = le.transform(y_test)

# Set up XGBDmatrix
dtrain = xgb.DMatrix(data=X_train.values, label=y_train_enc)
dtest  = xgb.DMatrix(data=X_test.values,  label=y_test_enc)

params = {
        "objective": "binary:logistic", # Set objective
        "eval_metric": ["auc", "error"],  # Track both AUC and error
        "seed": 42, # set seed

    }
num_boost_round = 100 # Set number of rounds

watchlist = [(dtrain, "train")] # Set data for evaluation
booster = xgb.train(params, # Set parameters
                    dtrain,  # Set training data
                    num_boost_round=num_boost_round, # Set number of rounds
                    evals=watchlist,  # Set data to evaluate on
                    verbose_eval=50) # Set print out frequency

test_pred_raw = booster.predict(dtest) # Create predictions
test_pred_raw

# Convert predictions into classes at 0.5
test_pred_cls = (test_pred_raw >= 0.5).astype(int)

print("\nConfusion matrix:")
cm = (confusion_matrix(y_test_enc, test_pred_cls))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_) # Set class labels
disp.plot(cmap="Blues") # Set color map
plt.title("Confusion Matrix — XGBoost") # Set title
plt.show() # Display plot
print("\nAccuracy):")
print(accuracy_score(y_test_enc, test_pred_cls)) # Get classification report

"""**XG BOOST TUNED**"""

params = {
    "objective": "binary:logistic",   # Set objective
    "eta": 0.1,                       # Set learning rate
    "eval_metric": ["auc", "error"],  # Track both AUC and error
    "tree_method": "hist",
    "seed": 111111,
    "nthread": 1,                     # Parallel threads
}

# Run CV inside XGBoost
cv_res = xgb.cv(
    params=params,
    dtrain=dtrain,              # Training data (DMatrix)
    num_boost_round=400,       # Number of rounds
    nfold=5,                    # 5-fold CV
    verbose_eval=20,            # Print every 20 iters
    stratified=True,            # Good practice for classification
    shuffle=True,
)

# Identify best iteration
best_idx = cv_res['test-error-mean'].idxmin()
best_iter = int(best_idx) + 1 # Increment by 1 to get iteration
best_err  = float(cv_res.loc[best_idx, 'test-error-mean']) # Extract test error
best_auc  = float(cv_res.loc[best_idx, 'test-auc-mean']) if 'test-auc-mean' in cv_res.columns else np.nan # Extract test AUC

# Print results
print(f"Best iteration (by min test error): {best_iter}")
print(f"Min test error at best iter: {best_err:.6f}")
if not np.isnan(best_auc):
    print(f"Test AUC at best iter: {best_auc:.6f}")

df_plot = cv_res.reset_index().rename(columns={"index": "iter"})
df_plot["iter"] = df_plot["iter"] + 1  # 1-based

# Safe column names (hyphens -> underscores) and ribbon bounds
df_plot = df_plot.rename(columns=lambda c: c.replace("-", "_"))
df_plot["test_error_lower"] = df_plot["test_error_mean"] - df_plot["test_error_std"]
df_plot["test_error_upper"] = df_plot["test_error_mean"] + df_plot["test_error_std"]

# Create plot
p_err = (
    ggplot(df_plot, # Set data
           aes(x="iter", y="test_error_mean")) # Set X and Y
    + geom_line() # Set line
    + geom_ribbon(aes(ymin="test_error_lower", ymax="test_error_upper"), alpha=0.15) # Set error bounds
    + geom_vline(xintercept=best_iter, linetype="dashed", alpha=0.6) # Add vertical line at best iteration
    + theme_bw() # Set theme
    + labs( # Set labels
        title="XGBoost CV (no early stopping): Iterations vs Validation Error",
        x="Boosting iteration",
        y="Test error (mean ± 1 sd across folds)"
    )
)
# View plot
p_err

# Set ETA values to try
etas = [0.3, 0.1, 0.05, 0.01, 0.005]
# Set base parameters
base_params = {
    "objective": "binary:logistic",
    "eval_metric": ["auc", "error"],
    "tree_method": "hist",
    "seed": 111111,
    "nthread": 1,                  # single core
}

curves = []     # per-iteration logs for plotting
summaries = []  # one row per eta
# For each learning rate
for eta in tqdm(etas, desc="Learning-rate CV (serial)"):
    params = base_params.copy() # Create copy of parmameters
    params["eta"] = float(eta) # Update ETA value
    # Apply xgb.cv
    cv = xgb.cv(
        params=params, # Set parameters
        dtrain=dtrain, # Set training data
        num_boost_round=1000,  # run to 1000 unless ES stops early
        nfold=5, # Set folds for cross validation
        early_stopping_rounds=100, # Set early stopping rounds
        stratified=True,
        shuffle=True,
        verbose_eval=False,
        seed=111111,
    )

    # Extract data for model performance
    df_log = cv.reset_index().rename(columns={"index": "iter"})
    df_log["iter"] = df_log["iter"] + 1 # Increment iterations to get real number
    # fix hyphenated column names for plotnine
    df_log = df_log.rename(columns=lambda c: c.replace("-", "_"))
    df_log["eta"] = str(eta) # Store ETA value as a string
    curves.append(df_log) # Add values to data store

    # Identify best iteration
    best_round = len(cv)
    best_row = cv.iloc[best_round - 1] # Identify best row


    best_err = float(best_row["test-error-mean"]) # Extract best error value
    best_auc = float(best_row["test-auc-mean"]) # Extract best AUC value
    # Store results
    summaries.append({"eta": eta, "best_round": best_round, "test_error": best_err, "test_auc": best_auc})

# Combine curve data
curves_df = pd.concat(curves, ignore_index=True)
# Create data frame of result data
summ_df = pd.DataFrame(summaries).sort_values(
    ["test_error","test_auc"] ,
    ascending=[True, False]
).reset_index(drop=True)

display(summ_df.head())

# Precompute ribbons (mean ± 1 sd) per-eta
curves_df["y_lower"] = curves_df["test_error_mean"] - curves_df["test_error_std"]
curves_df["y_upper"] = curves_df["test_error_mean"] + curves_df["test_error_std"]

# Create plot
p_lr = (
    ggplot(curves_df,  # Set dataset
           aes(x="iter", y="test_error_mean", color="eta", group="eta")) # Set Aesthetics
    + geom_line() # Set geom line
    + geom_ribbon(aes(ymin="y_lower", ymax="y_upper", fill="eta"), linetype="dashed", alpha=0.1, color="grey") # Add error bars
    + theme_bw() # Set theme
    + labs( # Set labels
        title="Learning Curves: Iterations vs Validation Error by Learning Rate",
        x="Boosting iteration",
        y=("Test error (mean ± 1 sd)" ),
        color="eta", fill="eta"
    )
)
# Display plot
display(p_lr)

best_eta = float(summ_df.iloc[0]["eta"]) # Extract best learning rate
best_round = int(summ_df.iloc[0]["best_round"]) # Extract best round
print(f"Selected eta={best_eta} with best_round={best_round}, " # Print results
      f"test_error={summ_df.iloc[0]['test_error']:.6f}, "
      f"AUC={summ_df.iloc[0]['test_auc']:.6f}")

best_eta

params = {
    "objective": "binary:logistic",
    "eval_metric": ["auc", "error"],
    "eta": best_eta, # Use tuned value for eta
    "tree_method": "hist",
    "seed": 111111,
    "nthread": 1,                  # single core
}
# Set up XGBoost
watchlist = [(dtrain, "train")] # Set data for evaluation
# Apply model
xgb_tuned = xgb.train(params, # Set parameters
                    dtrain,  # Set training data
                    num_boost_round=503, # Set number of rounds to previous best round
                    evals=watchlist,  # Set data to evaluate on
                    verbose_eval=50) # Set print out frequency

# Predict using the tuned model
test_pred_tuned = xgb_tuned.predict(dtest)

# Convert probabilities to binary classes using 0.5 threshold
test_pred_cls_t = (test_pred_tuned >= 0.5).astype(int)

# Print confusion matrix
cm = confusion_matrix(y_test_enc, test_pred_cls_t)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap="Blues")
plt.title("Confusion Matrix — Tuned XGBoost")
plt.show()

# Print accuracy
accuracy = accuracy_score(y_test_enc, test_pred_cls_t)
print(f"Accuracy (Tuned XGBoost): {accuracy:.4f}")

"""**VARIBALE IMPORTANCE**"""

import shap
X_train_numeric = X_train.astype(float)
explainer = shap.TreeExplainer(xgb_tuned, data=X_train_numeric)
shap_values = explainer(X_train_numeric)

shap.plots.bar(shap_values, max_display=10)

"""ROC CURVE"""

# Get probabilities for the Bagging model
bag_pred_proba = bag_model.predict_proba(X_test)[:, 1]

# Get probabilities for the tuned XGBoost model
test_pred_tuned = xgb_tuned.predict(dtest)

pred_dict = {}
pred_dict['Bagging']  =  np.asarray(bag_pred_proba).ravel()
pred_dict['XGBoost Initial'] = np.asarray(test_pred_raw).ravel()
pred_dict['XGBoost Tuned'] = np.asarray(test_pred_tuned).ravel()


# Build ROC curves & AUCs
curves = [] # Create empty files to store results
aucs = {}
# For each set of predictions
for name, preds in pred_dict.items():
    # Use y_test_enc for roc_curve as it contains numerical labels
    fpr, tpr, _ = roc_curve(y_test_enc, preds) # Calculate ROC
    auc_val = roc_auc_score(y_test_enc, preds) # Calculate AUC
    aucs[name] = auc_val # Store AUC
    curves.append(pd.DataFrame({"fpr": fpr, "tpr": tpr, "Model": name})) # Store ROC

# Joine results to data frame
df_curves = pd.concat(curves, ignore_index=True);
# Put AUC in the legend label
df_curves["Label"] = df_curves["Model"].map(lambda m: f"{m} (AUC={aucs[m]:.3f})")

# Create plot
p_roc = (
    ggplot(df_curves,  # Set data frame
           aes(x="fpr", y="tpr", color="Label")) # Set aesthetics
    + geom_line(size=1.05, alpha=0.95) # Set geom_line
    + geom_abline(intercept=0, slope=1, linetype="dashed", alpha=0.6) # Set 45 degree line
    + coord_equal()
    + theme_classic()
    + theme(
        legend_position="bottom",
        legend_title=element_text(size=9),
        legend_text=element_text(size=9),
        axis_text=element_text(size=9),
        axis_title=element_text(size=10)
    )
    + labs( # Set labels
        title="ROC Curves on Test Set",
        x="False Positive Rate",
        y="True Positive Rate",
        color=""  # hide legend title
    )
)
# Generate plot
p_roc

g2 = (
    ggplot(df, aes(x='CRS_ELAPSED_TIME', fill='factor(DELAYED)')) +
    geom_density(alpha=0.5) +
    labs(x='Elapsed Time', title='Elapsed Time by Delay Status')
)


g2

g2 = (
    ggplot(df, aes(x='ELAPSED_TIME', fill='factor(DELAYED)')) +
    geom_density(alpha=0.5) +
    labs(x='Elapsed Time', title='Elapsed Time by Delay Status')
)


g2

g2 = (
    ggplot(df, aes(x='AIR_TIME', fill='factor(DELAYED)')) +
    geom_density(alpha=0.5) +
    labs(x='Elapsed Time', title='Elapsed Time by Delay Status')
)


g2

(ggplot(df, aes(x='DISTANCE', fill='factor(DELAYED)'))
+ geom_density(alpha=0.5)
+ labs(title='Scheduled Elapsed Time vs Delay', x='CRS_ELAPSED_TIME', fill='DELAYED')
+ theme_minimal())

from sklearn.metrics import roc_auc_score, accuracy_score

# --- Bagging Classifier ---
# Predict (already trained)
y_pred_bagging = bag_model.predict(X_test)
y_pred_bagging_proba = bag_model.predict_proba(X_test)[:, 1]  # for AUC

# Encode ground truth for AUC
y_test_enc = le.transform(y_test)

# Bagging scores
acc_bag = accuracy_score(y_test, y_pred_bagging)
error_bag = 1 - acc_bag
auc_bag = roc_auc_score(y_test_enc, y_pred_bagging_proba)

# --- XGBoost Default ---
# Already predicted: test_pred_cls and test_pred_raw
acc_xgb = accuracy_score(y_test_enc, test_pred_cls)
error_xgb = 1 - acc_xgb
auc_xgb = roc_auc_score(y_test_enc, test_pred_raw)

# --- XGBoost Tuned ---
acc_xgb_tuned = accuracy_score(y_test_enc, test_pred_cls_t)
error_xgb_tuned = 1 - acc_xgb_tuned
auc_xgb_tuned = roc_auc_score(y_test_enc, test_pred_tuned)

# --- Print Results ---
print(f"Bagging Classifier      - Accuracy: {acc_bag:.4f}, Test Error: {error_bag:.4f}, AUC: {auc_bag:.4f}")
print(f"XGBoost (Default)       - Accuracy: {acc_xgb:.4f}, Test Error: {error_xgb:.4f}, AUC: {auc_xgb:.4f}")
print(f"XGBoost (Tuned)         - Accuracy: {acc_xgb_tuned:.4f}, Test Error: {error_xgb_tuned:.4f}, AUC: {auc_xgb_tuned:.4f}")